# Now I'll try the histogram function on just one column, d$Game1Angry1.
unique(vector_of_Game1Angry1)
range(vector_of_Game1Angry1)
hist(vector_of_Game1Angry1)
# I learn that the likert scores range from 1 to 7 for that SINGLE column.
# Now, I'll do the same process, but on all the columns, not just one column.
# I can tell R to select all the likert values between the 7th column of the dataset and the 70th column of the dataset, and to make a single vector using the c() function.
vector_of_all_likert_scores <- c(d[,7:70], recursive = TRUE, use.names = FALSE)
length(vector_of_all_likert_scores)
# Now I'll try the same functions on all the likert scores. The unique and hist functions took too long to caclulate, so I ended up just using the range function.
# range(vector_of_all_likert_scores)
# unique(vector_of_all_likert_scores)
hist(vector_of_all_likert_scores)
tail(d)
filtered_d = d %>%
filter(is.na(DoNotUse))  # your code here: exclude subjects that are marked as "DoNotUse"
filtered_d = filtered_d %>%
select(c("Subject", "Cond"), # Generally important columns for both hypotheses
contains("Game"), # we want all the game columns for hypothesis 1
-contains("Intro"), -c("WhichGames", "GameComments"), # except these
starts_with("DinerDashWith"), c("SOFMusicEnemies", "SOFNoMusicEnemies")) # These columns are for hypothesis 2
rating_hyp_d = filtered_d %>%
filter(is.na(DoNotUseVideoGamePerformanceData)) %>% # first, let's get rid of the subjects who did so poorly on one game that their data is unusable
select(-DoNotUseVideoGamePerformanceData, # now get rid of that column
-starts_with("DinerDash"), # and the other columns we don't need
-starts_with("SOF"))
performance_hyp_d = filtered_d %>%
select(-contains("Game")) # your code here: remove the columns containing "Game" in the name
tiny_demo_d = head(performance_hyp_d, 2) # get just the first two subjects performance data, for a demo
tiny_demo_d
tiny_demo_d %>% gather(Measurement, Value,
-c("Subject", "Cond")) # this tells it to gather all columns *except* these ones.
performance_hyp_long_d = performance_hyp_d %>%
gather(Measurement, Score, -c("Subject", "Cond"))
rating_hyp_long_d = rating_hyp_d %>%
gather(Measurement, Rating, -c("Subject", "Cond"))
performance_hyp_long_d = performance_hyp_long_d %>%
mutate(ConfrontationalGame = grepl("SOF", Measurement), # create a new variable that will say whether the measurement was of the game soldier of fortune (SOF).
WithMusic = !grepl("NoMusic|WithoutMusic", Measurement), # creates a new column named WithMusic, which is False if the measurement contains *either* "NoMusic" or "WithoutMusic"
MusicCondition = factor(ifelse(Cond > 3, Cond-3, Cond), levels = 1:3, labels = c("Anger", "Exciting", "Neutral"))) # Get rid of uninterpretable condition labels
rating_hyp_long_d = rating_hyp_long_d %>%
mutate(
IsRecall = grepl("Friends|Strangers", Measurement)
)
rating_hyp_long_d = rating_hyp_long_d %>%
mutate(
GameNumber = as.numeric(substr(rating_hyp_long_d$Measurement, 5, 5)),
ConfrontationalGame = GameNumber <= 2, # in a mutate, we can use a column we created (or changed) right away. Games 1 and 2 are confrontational, games 3 and 4 are not.
Emotion = str_extract(Measurement, "Angry|Neutral|Excited|Exciting|Calm"),
Emotion = ifelse(Emotion == "Excited", "Exciting", # this just gets rid of some annoying labeling choices
ifelse(Emotion == "Calm", "Neutral", Emotion))
)
performance_hyp_long_d %>%
group_by(ConfrontationalGame) %>%
summarize(AvgScore = mean(Score, na.rm=T)) # the na.rm tells R to ignore NA values
performance_hyp_long_d = performance_hyp_long_d %>%
group_by(ConfrontationalGame, WithMusic) %>% # we're going to compute four sets of z-scores, one for the confrontational game without music, one for the confrontational game with, one for the nonconfrontational game without music, and one for the nonconfrontational game with
mutate(z_scored_performance = scale(Score)) %>%
ungroup()
rating_summary_d = rating_hyp_long_d %>%
group_by(ConfrontationalGame, Emotion) %>%
summarize(MeanRating = mean(Rating, na.rm=T))
rating_summary_d
ggplot(rating_summary_d, aes(x=ConfrontationalGame, y= MeanRating, fill=Emotion)) +
geom_bar(position="dodge", stat="identity") +
scale_fill_brewer(palette="Set1")
model = lm(Rating ~ ConfrontationalGame * Emotion, rating_hyp_long_d)
summary(model)
performance_diff_d = performance_hyp_long_d %>%
mutate(WithMusic = factor(WithMusic, levels=c(F, T), labels=c("PreMusic", "PostMusic"))) %>% # first, tweak the variable so our code is easier to read.
select(-c("Score", "Measurement")) %>% # now we remove columns we don't need (bonus: leave them in and see if you can understand what goes wrong!)
spread(WithMusic, z_scored_performance) %>%
mutate(ImprovementScore=PostMusic-PreMusic)
performance_diff_d
performance_diff_summary_d = performance_diff_d %>%
group_by(ConfrontationalGame, MusicCondition) %>%
summarize(MeanImprovementScore = mean(ImprovementScore, na.rm=T))
performance_diff_summary_d
ggplot(performance_diff_summary_d, aes(x=ConfrontationalGame, y=MeanImprovementScore, fill=MusicCondition)) +
geom_bar(position="dodge", stat="identity") +
scale_fill_brewer(palette="Set1")
performance_model = lm(ImprovementScore ~ ConfrontationalGame * MusicCondition, performance_diff_d)
summary(performance_model)
library(foreign) # for reading spss formatted data
library(tidyr)
library(dplyr)
library(stringr) # useful for some string manipulation
library(ggplot2)
d = read.spss("Tamiretal2008ReplicationData.sav", to.data.frame=T)
head(d)
colnames(d)
# First, I'll make a vector with all the likert values in d$Game1Angry1, which is the 7th column of the dataset
vector_of_Game1Angry1 <- d[,7]
length(vector_of_Game1Angry1)
print(vector_of_Game1Angry1)
# Now I'll try the histogram function on just one column, d$Game1Angry1.
unique(vector_of_Game1Angry1)
range(vector_of_Game1Angry1)
hist(vector_of_Game1Angry1)
# I learn that the likert scores range from 1 to 7 for that SINGLE column.
# Now, I'll do the same process, but on all the columns with likert ratings, not just one column.
# I can tell R to select all the likert values between the 7th column of the dataset and the 70th column of the dataset, and to make a single vector using the c() function.
vector_of_all_likert_scores <- c(d[,7:70], recursive = TRUE, use.names = FALSE)
length(vector_of_all_likert_scores)
# Now I'll try the hist functions on all the likert scores.
# range(vector_of_all_likert_scores)
# unique(vector_of_all_likert_scores)
hist(vector_of_all_likert_scores)
tail(d)
filtered_d = d %>%
filter(is.na(DoNotUse))  # your code here: exclude subjects that are marked as "DoNotUse"
filtered_d = filtered_d %>%
select(c("Subject", "Cond"), # Generally important columns for both hypotheses
contains("Game"), # we want all the game columns for hypothesis 1
-contains("Intro"), -c("WhichGames", "GameComments"), # except these
starts_with("DinerDashWith"), c("SOFMusicEnemies", "SOFNoMusicEnemies")) # These columns are for hypothesis 2
rating_hyp_d = filtered_d %>%
filter(is.na(DoNotUseVideoGamePerformanceData)) %>% # first, let's get rid of the subjects who did so poorly on one game that their data is unusable
select(-DoNotUseVideoGamePerformanceData, # now get rid of that column
-starts_with("DinerDash"), # and the other columns we don't need
-starts_with("SOF"))
performance_hyp_d = filtered_d %>%
select(-contains("Game")) # your code here: remove the columns containing "Game" in the name
tiny_demo_d = head(performance_hyp_d, 2) # get just the first two subjects performance data, for a demo
tiny_demo_d
tiny_demo_d %>% gather(Measurement, Value,
-c("Subject", "Cond")) # this tells it to gather all columns *except* these ones.
performance_hyp_long_d = performance_hyp_d %>%
gather(Measurement, Score, -c("Subject", "Cond"))
rating_hyp_long_d = rating_hyp_d %>%
gather(Measurement, Rating, -c("Subject", "Cond"))
performance_hyp_long_d = performance_hyp_long_d %>%
mutate(ConfrontationalGame = grepl("SOF", Measurement), # create a new variable that will say whether the measurement was of the game soldier of fortune (SOF).
WithMusic = !grepl("NoMusic|WithoutMusic", Measurement), # creates a new column named WithMusic, which is False if the measurement contains *either* "NoMusic" or "WithoutMusic"
MusicCondition = factor(ifelse(Cond > 3, Cond-3, Cond), levels = 1:3, labels = c("Anger", "Exciting", "Neutral"))) # Get rid of uninterpretable condition labels
rating_hyp_long_d = rating_hyp_long_d %>%
mutate(
IsRecall = grepl("Friends|Strangers", Measurement)
)
rating_hyp_long_d = rating_hyp_long_d %>%
mutate(
GameNumber = as.numeric(substr(rating_hyp_long_d$Measurement, 5, 5)),
ConfrontationalGame = GameNumber <= 2, # in a mutate, we can use a column we created (or changed) right away. Games 1 and 2 are confrontational, games 3 and 4 are not.
Emotion = str_extract(Measurement, "Angry|Neutral|Excited|Exciting|Calm"),
Emotion = ifelse(Emotion == "Excited", "Exciting", # this just gets rid of some annoying labeling choices
ifelse(Emotion == "Calm", "Neutral", Emotion))
)
performance_hyp_long_d %>%
group_by(ConfrontationalGame) %>%
summarize(AvgScore = mean(Score, na.rm=T)) # the na.rm tells R to ignore NA values
performance_hyp_long_d = performance_hyp_long_d %>%
group_by(ConfrontationalGame, WithMusic) %>% # we're going to compute four sets of z-scores, one for the confrontational game without music, one for the confrontational game with, one for the nonconfrontational game without music, and one for the nonconfrontational game with
mutate(z_scored_performance = scale(Score)) %>%
ungroup()
rating_summary_d = rating_hyp_long_d %>%
group_by(ConfrontationalGame, Emotion) %>%
summarize(MeanRating = mean(Rating, na.rm=T))
rating_summary_d
ggplot(rating_summary_d, aes(x=ConfrontationalGame, y= MeanRating, fill=Emotion)) +
geom_bar(position="dodge", stat="identity") +
scale_fill_brewer(palette="Set1")
model = lm(Rating ~ ConfrontationalGame * Emotion, rating_hyp_long_d)
summary(model)
performance_diff_d = performance_hyp_long_d %>%
mutate(WithMusic = factor(WithMusic, levels=c(F, T), labels=c("PreMusic", "PostMusic"))) %>% # first, tweak the variable so our code is easier to read.
select(-c("Score", "Measurement")) %>% # now we remove columns we don't need (bonus: leave them in and see if you can understand what goes wrong!)
spread(WithMusic, z_scored_performance) %>%
mutate(ImprovementScore=PostMusic-PreMusic)
performance_diff_d
performance_diff_summary_d = performance_diff_d %>%
group_by(ConfrontationalGame, MusicCondition) %>%
summarize(MeanImprovementScore = mean(ImprovementScore, na.rm=T))
performance_diff_summary_d
ggplot(performance_diff_summary_d, aes(x=ConfrontationalGame, y=MeanImprovementScore, fill=MusicCondition)) +
geom_bar(position="dodge", stat="identity") +
scale_fill_brewer(palette="Set1")
performance_model = lm(ImprovementScore ~ ConfrontationalGame * MusicCondition, performance_diff_d)
summary(performance_model)
install.packages("devtools")
devtools::install_github("TomHardwicke/ReproReports")
library("ReproReports")
devtools::install_github("TomHardwicke/ReproReports")
library("ReproReports")
install.packages("devtools")
devtools::install_github("TomHardwicke/ReproReports")
library("ReproReports")
install.packages("devtools")
devtools::install_github("TomHardwicke/ReproReports")
force = TRUE
TRUE
"force = TRUE"
force = TRUE
devtools::install_github("TomHardwicke/ReproReports")
devtools::install_github("TomHardwicke/ReproReports"), force = TRUE
devtools::install_github("TomHardwicke/ReproReports") force = TRUE
devtools::install_github("TomHardwicke/ReproReports") force = TRUE
devtools::install_github("TomHardwicke/ReproReports")
force = TRUE
library("ReproReports")
install.packages("devtools")
devtools::install_github("TomHardwicke/ReproReports")
devtools::install_github("TomHardwicke/ReproReports", force = TRUE)
library("ReproReports")
library("ReproReports")
install.packages(c("backports", "covr", "curl", "digest", "htmltools", "htmlwidgets", "later", "markdown", "pkgbuild", "pkgconfig", "promises", "rmarkdown", "shiny", "tinytex", "xfun"))
library("ReproReports")
library("devtools")
devtools::install_github("TomHardwicke/ReproReports")
library(ReproReports)
ReproReports::reproCheck()
session_info()
articleID <- "6-1-2015" # insert the article ID code here e.g., "10-3-2015"
reportType <- "Pilot" # specify whether this is the 'pilot' report or 'copilot' report
pilotNames <- "Cristina Ceballos" # insert the pilot's name here e.g., "Tom Hardwicke".
copilotNames <- "Insub Kim" # # insert the co-pilot's name here e.g., "Michael Frank".
pilotTTC <- 120 # insert the pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
copilotTTC <- NA # insert the co-pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
pilotStartDate <- "11/3/2019" # insert the piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- NA # insert the co-piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- NA # insert the date of final report completion in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(ReproReports) # custom reporting functions
library(foreign)
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
data <- read_excel("GroupA_6-1-2015/data/data_Exp1.xlsx", sheet = "summary")
head(data)
colnames(data)
articleID <- "6-1-2015" # insert the article ID code here e.g., "10-3-2015"
reportType <- "copilot" # specify whether this is the 'pilot' report or 'copilot' report
pilotNames <- "Cristina Ceballos" # insert the pilot's name here e.g., "Tom Hardwicke".
copilotNames <- "Insub Kim" # # insert the co-pilot's name here e.g., "Michael Frank".
pilotTTC <- 520 # insert the pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
copilotTTC <- 180 # insert the co-pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
pilotStartDate <- "11/3/2019" # insert the piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- "11/10/2019" # insert the co-piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- "11/10/2019"  # insert the date of final report completion in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(ReproReports) # custom reporting functions
library(foreign)
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
data <- read_excel("data/data_Exp1.xlsx", sheet = "summary")
articleID <- "6-1-2015" # insert the article ID code here e.g., "10-3-2015"
reportType <- "Pilot" # specify whether this is the 'pilot' report or 'copilot' report
pilotNames <- "Cristina Ceballos" # insert the pilot's name here e.g., "Tom Hardwicke".
copilotNames <- "Insub Kim" # # insert the co-pilot's name here e.g., "Michael Frank".
pilotTTC <- 520 # insert the pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
copilotTTC <- 180 # insert the co-pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
pilotStartDate <- "11/3/2019" # insert the piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- "11/10/2019" # insert the co-piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- "11/10/2019" # insert the date of final report completion in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(ReproReports) # custom reporting functions
library(foreign)
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
data <- read_excel("GroupA_6-1-2015/data/data_Exp1.xlsx", sheet = "summary")
head(data)
# Right now, the data is arranged in wide format. I want to make it longer, so I will use pivot_longer to make it tidy.
# But first, I have to manually modify the columns and assign each column a column name. To do so, I created a new Excel file called "data_Exp1_modified". In this Excel file, I manually renamed each column. For example, the first column was called "closedloop_grasping_uncrowded_3cm". The other columns followed the same naming rules.
# In the Excel file, I also deleted empty columns. I also removed the two top columns.
# I use the read_excel function to read the data.
data_modified <- read_excel("GroupA_6-1-2015/data/data_Exp1_modified.xlsx", sheet = "summary")
# Now I use the functions "separate" and "pivot_longer" to make my data tidy.
pivoted_data <- pivot_longer(data_modified, closedloop_grasping_uncrowded_3cm:openloop_estimation_crowded_3.75cm, names_to = "column", values_to="estimate")
tidy_data <- separate(pivoted_data, column, into = c("open_closed","grasping_estimating","crowded_uncrowded","cm"), sep = "_")
colnames(tidy_data)
# Now my data is tidy!
# To run the ANOVA, I should get rid of the "means" information in the tidy_data. To do that, I simply selected the first 160 rows of the dataset, and ommitted the bottom rows 161-176, since those are the rows that have the means.
ANOVA_tidy_data <- tidy_data[1:160,]
# "ANOVA_tidy_data is the dataset I will use for the ANOVA analysis. It excludes the "means" rows.
# Next, I created a dataset that has ONLY the "means" information, since that is the information used in Figure 3.
Fig3_tidy_data <- tidy_data[161:176,]
# "Fig3_tidy_data is the dataset I will use for try to recreate Fig3 from the paper. It has only the "means" rows.
# I used the aov function to
ANOVA_results <- aov(estimate ~ grasping_estimating * crowded_uncrowded * open_closed * cm, ANOVA_tidy_data)
summary(ANOVA_results)
colnames(Fig3_tidy_data)
# plot("cm", Fig3_tidy_data[10:16], Fig3_tidy_data,  "l")
# commented out because I could not get the code to work
# Reprocheck for the four-way ANOVA F value:
reproCheck("6.818", "2.662", valueType = "F")
# Reprocheck for the four-way ANOVA p value:
reproCheck("0.28", "0.105", valueType = "p")
reportObject <- reportObject %>%
filter(dummyRow == FALSE) %>% # remove the dummy row
select(-dummyRow) %>% # remove dummy row designation
mutate(articleID = articleID) %>% # add variables to report
select(articleID, everything()) # make articleID first column
# decide on final outcome
if(any(reportObject$comparisonOutcome %in% c("MAJOR_ERROR", "DECISION_ERROR"))){
finalOutcome <- "Failure"
}else{
finalOutcome <- "Success"
}
# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, finalOutcome)
# save report objects
if(reportType == "pilot"){
write_csv(reportObject, "pilotReportDetailed.csv")
write_csv(reportExtras, "pilotReportExtras.csv")
}
if(reportType == "copilot"){
write_csv(reportObject, "copilotReportDetailed.csv")
write_csv(reportExtras, "copilotReportExtras.csv")
}
articleID <- "6-1-2015" # insert the article ID code here e.g., "10-3-2015"
reportType <- "Pilot" # specify whether this is the 'pilot' report or 'copilot' report
pilotNames <- "Cristina Ceballos" # insert the pilot's name here e.g., "Tom Hardwicke".
copilotNames <- "Insub Kim" # # insert the co-pilot's name here e.g., "Michael Frank".
pilotTTC <- 520 # insert the pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
copilotTTC <- 180 # insert the co-pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
pilotStartDate <- "11/3/2019" # insert the piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- "11/10/2019" # insert the co-piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- "11/10/2019" # insert the date of final report completion in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(ReproReports) # custom reporting functions
library(foreign)
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
data <- read_excel("GroupA_6-1-2015/data/data_Exp1.xlsx", sheet = "summary")
head(data)
# Right now, the data is arranged in wide format. I want to make it longer, so I will use pivot_longer to make it tidy.
# But first, I have to manually modify the columns and assign each column a column name. To do so, I created a new Excel file called "data_Exp1_modified". In this Excel file, I manually renamed each column. For example, the first column was called "closedloop_grasping_uncrowded_3cm". The other columns followed the same naming rules.
# In the Excel file, I also deleted empty columns. I also removed the two top columns.
# I use the read_excel function to read the data.
data_modified <- read_excel("GroupA_6-1-2015/data/data_Exp1_modified.xlsx", sheet = "summary")
# Now I use the functions "separate" and "pivot_longer" to make my data tidy.
pivoted_data <- pivot_longer(data_modified, closedloop_grasping_uncrowded_3cm:openloop_estimation_crowded_3.75cm, names_to = "column", values_to="estimate")
tidy_data <- separate(pivoted_data, column, into = c("open_closed","grasping_estimating","crowded_uncrowded","cm"), sep = "_")
colnames(tidy_data)
# Now my data is tidy!
# To run the ANOVA, I should get rid of the "means" information in the tidy_data. To do that, I simply selected the first 160 rows of the dataset, and ommitted the bottom rows 161-176, since those are the rows that have the means.
ANOVA_tidy_data <- tidy_data[1:160,]
# "ANOVA_tidy_data is the dataset I will use for the ANOVA analysis. It excludes the "means" rows.
# Next, I created a dataset that has ONLY the "means" information, since that is the information used in Figure 3.
Fig3_tidy_data <- tidy_data[161:176,]
# "Fig3_tidy_data is the dataset I will use for try to recreate Fig3 from the paper. It has only the "means" rows.
# I used the aov function to
ANOVA_results <- aov(estimate ~ grasping_estimating * crowded_uncrowded * open_closed * cm, ANOVA_tidy_data)
summary(ANOVA_results)
colnames(Fig3_tidy_data)
# plot("cm", Fig3_tidy_data[10:16], Fig3_tidy_data,  "l")
# commented out because I could not get the code to work
# Reprocheck for the four-way ANOVA F value:
reproCheck("6.818", "2.662", valueType = "F")
# Reprocheck for the four-way ANOVA p value:
reproCheck("0.28", "0.105", valueType = "p")
reportObject <- reportObject %>%
filter(dummyRow == FALSE) %>% # remove the dummy row
select(-dummyRow) %>% # remove dummy row designation
mutate(articleID = articleID) %>% # add variables to report
select(articleID, everything()) # make articleID first column
# decide on final outcome
if(any(reportObject$comparisonOutcome %in% c("MAJOR_ERROR", "DECISION_ERROR"))){
finalOutcome <- "Failure"
}else{
finalOutcome <- "Success"
}
# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, finalOutcome)
# save report objects
if(reportType == "pilot"){
write_csv(reportObject, "pilotReportDetailed.csv")
write_csv(reportExtras, "pilotReportExtras.csv")
}
if(reportType == "copilot"){
write_csv(reportObject, "copilotReportDetailed.csv")
write_csv(reportExtras, "copilotReportExtras.csv")
}
devtools::session_info()
articleID <- "6-1-2015" # insert the article ID code here e.g., "10-3-2015"
reportType <- "copilot" # specify whether this is the 'pilot' report or 'copilot' report
pilotNames <- "Cristina Ceballos" # insert the pilot's name here e.g., "Tom Hardwicke".
copilotNames <- "Insub Kim" # # insert the co-pilot's name here e.g., "Michael Frank".
pilotTTC <- 520 # insert the pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
copilotTTC <- 180 # insert the co-pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
pilotStartDate <- "11/3/2019" # insert the piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- "11/10/2019" # insert the co-piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- "11/10/2019"  # insert the date of final report completion in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(ReproReports) # custom reporting functions
library(foreign)
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
data <- read_excel("data/data_Exp1.xlsx", sheet = "summary")
articleID <- "6-1-2015" # insert the article ID code here e.g., "10-3-2015"
reportType <- "Pilot" # specify whether this is the 'pilot' report or 'copilot' report
pilotNames <- "Cristina Ceballos" # insert the pilot's name here e.g., "Tom Hardwicke".
copilotNames <- "Insub Kim" # # insert the co-pilot's name here e.g., "Michael Frank".
pilotTTC <- 520 # insert the pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
copilotTTC <- 180 # insert the co-pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
pilotStartDate <- "11/3/2019" # insert the piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- "11/10/2019" # insert the co-piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- "11/10/2019" # insert the date of final report completion in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(ReproReports) # custom reporting functions
library(foreign)
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
data <- read_excel("GroupA_6-1-2015/data/data_Exp1.xlsx", sheet = "summary")
head(data)
# Right now, the data is arranged in wide format. I want to make it longer, so I will use pivot_longer to make it tidy.
# But first, I have to manually modify the columns and assign each column a column name. To do so, I created a new Excel file called "data_Exp1_modified". In this Excel file, I manually renamed each column. For example, the first column was called "closedloop_grasping_uncrowded_3cm". The other columns followed the same naming rules.
# In the Excel file, I also deleted empty columns. I also removed the two top columns.
# I use the read_excel function to read the data.
data_modified <- read_excel("GroupA_6-1-2015/data/data_Exp1_modified.xlsx", sheet = "summary")
# Now I use the functions "separate" and "pivot_longer" to make my data tidy.
pivoted_data <- pivot_longer(data_modified, closedloop_grasping_uncrowded_3cm:openloop_estimation_crowded_3.75cm, names_to = "column", values_to="estimate")
tidy_data <- separate(pivoted_data, column, into = c("open_closed","grasping_estimating","crowded_uncrowded","cm"), sep = "_")
colnames(tidy_data)
# Now my data is tidy!
# To run the ANOVA, I should get rid of the "means" information in the tidy_data. To do that, I simply selected the first 160 rows of the dataset, and ommitted the bottom rows 161-176, since those are the rows that have the means.
ANOVA_tidy_data <- tidy_data[1:160,]
# "ANOVA_tidy_data is the dataset I will use for the ANOVA analysis. It excludes the "means" rows.
# Next, I created a dataset that has ONLY the "means" information, since that is the information used in Figure 3.
Fig3_tidy_data <- tidy_data[161:176,]
# "Fig3_tidy_data is the dataset I will use for try to recreate Fig3 from the paper. It has only the "means" rows.
# I used the aov function to
ANOVA_results <- aov(estimate ~ grasping_estimating * crowded_uncrowded * open_closed * cm, ANOVA_tidy_data)
summary(ANOVA_results)
colnames(Fig3_tidy_data)
# plot("cm", Fig3_tidy_data[10:16], Fig3_tidy_data,  "l")
# commented out because I could not get the code to work
# Reprocheck for the four-way ANOVA F value:
reproCheck("6.818", "2.662", valueType = "F")
# Reprocheck for the four-way ANOVA p value:
reproCheck("0.28", "0.105", valueType = "p")
reportObject <- reportObject %>%
filter(dummyRow == FALSE) %>% # remove the dummy row
select(-dummyRow) %>% # remove dummy row designation
mutate(articleID = articleID) %>% # add variables to report
select(articleID, everything()) # make articleID first column
# decide on final outcome
if(any(reportObject$comparisonOutcome %in% c("MAJOR_ERROR", "DECISION_ERROR"))){
finalOutcome <- "Failure"
}else{
finalOutcome <- "Success"
}
# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, finalOutcome)
# save report objects
if(reportType == "pilot"){
write_csv(reportObject, "pilotReportDetailed.csv")
write_csv(reportExtras, "pilotReportExtras.csv")
}
if(reportType == "copilot"){
write_csv(reportObject, "copilotReportDetailed.csv")
write_csv(reportExtras, "copilotReportExtras.csv")
}
devtools::session_info()
setwd("C:/Users/C. Ceballos/OneDrive - Leland Stanford Junior University/Year 4 2019-2020/PSYCH251_HWs/problem_sets")
library(tidyverse)
library(tidyverse)
averages <- numeric(10000)
for (i in 1:10000) {
X <- rnorm(30, 0, 1)
averages[i] <- mean(X)
}
averages <- numeric(10000)
for (i in 1:10000) {
X <- rnorm(30, 0, 1)
averages[i] <- mean(X)
}
averages
averages <- numeric(10000)
for (i in 1:10000) {
X <- rnorm(30, 0, 1)
averages[i] <- mean(X)
}
averages <- numeric(10000)
for (i in 1:10000) {
X <- rnorm(30, 0, 1)
averages[i] <- (X)
}
